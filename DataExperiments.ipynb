{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to experiment with loading in data programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('repo_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dfs = []\n",
    "for dir, subdir, files in os.walk('repo_data/'):\n",
    "    print(\"directory\", dir)\n",
    "    # print(\"subdirectory\", subdir)\n",
    "    # print(\"files\", files)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            # print(\"file\", file)\n",
    "            df = pd.read_csv(os.path.join(dir, file))\n",
    "            df['file_path'] = os.path.join(dir, file)\n",
    "            df['directory'] = dir\n",
    "            initial_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(initial_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.directory.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need to subset the data to only include repositories related to teaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_pedagogy_terms = [\n",
    "    \"pedagogy\",\n",
    "    \"teaching\",\n",
    "    \"education\",\n",
    "    \"learning\",\n",
    "    \"curriculum\",\n",
    "    \"instruction\",\n",
    "    \"syllabus\",\n",
    "    \"paper\",\n",
    "    \"class\",\n",
    "    \"course\",\n",
    "    \"lesson\",\n",
    "    \"lecture\",\n",
    "    \"semester\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower casing description and names, loop through each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"lower_description\"] = combined_df[\"description\"].str.lower()\n",
    "combined_df[\"lower_name\"] = combined_df[\"name\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_combined = []\n",
    "for term in potential_pedagogy_terms:\n",
    "    selected_rows = combined_df[(combined_df[\"lower_description\"].str.contains(term)) | (combined_df[\"lower_name\"].str.contains(term))]\n",
    "    print(term, len(selected_rows))\n",
    "    dfs_combined.append(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pedagogy_df = pd.concat(dfs_combined)\n",
    "combined_pedagogy_df = combined_pedagogy_df.drop_duplicates(subset=['id'])\n",
    "combined_pedagogy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pedagogy_df.to_csv('combined_pedagogy_data.csv',index=False)\n",
    "\n",
    "# Im not sure this df was read into the csv in the way we want (?)\n",
    "# Im understanding the dataframe better than the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Research Questions / Aims and Next Coding Steps\n",
    "- Data Collected !  {combined_pedagogy_data.csv})\n",
    "- Skills Analyzed   (skills being taught to students, return to Hack/Tact/Yack, do a Hack/Tact/Yack word count analysis of Dataset 1)\n",
    "- Pedagogy Analyzed  (Pedagogical Practices Considered, do a Pedagogy Approaches word count analysis of the combined pedagogy data) \n",
    "- Present Current Practices, what skills are most taught, what pedagogical approaches most used\n",
    "- Best Practices Evaluation: what are instructor / pedagogical goals? what skills are most effective at achieving instructor goals? What pedagogical approaches are most effective in students achieving certain skills and/or reaching pedagogical goals? \n",
    "    - value of interviews here, qualitative questions about big picture goals (not just \"i want my dh students to learn coding/python\" but also \"i want them to think algorithmically / understand affordances and limitations of digital methods / do x kind of research...\" )\n",
    "    - similar qualitative research / questions about if students were able to meet these goals and through what skills and what pedagogical approaches (ie learning python loops helped and so did group projects)\n",
    "    - maybe we want to limit questions to success of just teaching concrete skills through which approaches (ie coding + projects, not history of the field through group reflection posting)\n",
    "- Owen Next Step ? --> Hack Tact Yack word count breakdowns for repo_data and Pedagogy Approach word breakdown for combined_pedagogy data_csv or df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack Word Count within pedagogy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_hack_terms = [\n",
    "    'construct',\n",
    "    'create',\n",
    "    'stand up',\n",
    "    'web application',\n",
    "    'interface',\n",
    "    'web design',\n",
    "    'coding',\n",
    "    'computation',\n",
    "    'programming',\n",
    "    'algorithm',\n",
    "    'processing',\n",
    "    'machine learning',\n",
    "    'software development',\n",
    "    'data analysis',\n",
    "    'text analysis',\n",
    "    'network analysis',\n",
    "    'archive',\n",
    "    'dataset',\n",
    "    'maps',\n",
    "    'visualization',\n",
    "    'techniques',\n",
    "    'python',\n",
    "    'django',\n",
    "    'omeka',\n",
    "    'GitHub',\n",
    "    'Safari Techbooks',\n",
    "    'Developer Networks',\n",
    "    'Programming Environment',\n",
    "    'Mozilla',\n",
    "    'Anaconda',\n",
    "    'GIS',\n",
    "    'Visual Studio Code',\n",
    "    'TEI',\n",
    "    'SQL',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pedagogy_repo_data = pd.read_csv(\n",
    "    \"combined_pedagogy_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_hack = []\n",
    "for term in potential_hack_terms:\n",
    "    selected_rows = combined_pedagogy_repo_data[(combined_pedagogy_repo_data[\"lower_description\"].str.contains(term)) | (combined_pedagogy_repo_data c[\"lower_name\"].str.contains(term))]\n",
    "    print(term, len(selected_rows))\n",
    "    dfs_digital_history.append(selected_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming-pedagogies-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a8dc2a08ead06166a4c75a2328a5279eb8f82393aa59d17d9fd69598e1fc41a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
